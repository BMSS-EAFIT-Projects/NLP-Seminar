{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e419b78",
   "metadata": {},
   "source": [
    "Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5af7aa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de17e3b5",
   "metadata": {},
   "source": [
    "Archivos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a66e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = r\"C:\\Users\\afpue\\Documents\\Seminario NLP\\NLP\\publicaciones\\binaria.xlsx\"\n",
    "df = pd.read_excel(archivo)\n",
    "\n",
    "def limpiar(texto):\n",
    "    texto = texto.lower()\n",
    "    return re.findall(r'\\b\\w+\\b', texto)\n",
    "\n",
    "docs = df['Documento'].apply(limpiar).tolist()\n",
    "clases = df['Clase'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d25cb",
   "metadata": {},
   "source": [
    "Tweet de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf7138c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevo_procesado = limpiar(df.iloc[-1]['Documento'])\n",
    "clase_real = df.iloc[-1]['Clase']\n",
    "\n",
    "docs = df.iloc[:-1]['Documento'].apply(limpiar).tolist()\n",
    "clases = df.iloc[:-1]['Clase'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c737ff",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e339702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(D, C):\n",
    "    \"\"\"\n",
    "    Entrena un clasificador Multinomial Naive Bayes con add-1 smoothing.\n",
    "\n",
    "    Parámetros:\n",
    "    - D: lista de documentos (listas de palabras)\n",
    "    - C: lista de clases\n",
    "\n",
    "    Retorna:\n",
    "    - V: vocabulario (lista de palabras únicas)\n",
    "    - logprior: log P(c)\n",
    "    - loglikelihood: log P(w|c)\n",
    "    \"\"\"\n",
    "    N_doc = len(D)\n",
    "    logprior = {}\n",
    "    loglikelihood = {}\n",
    "    bigdoc = defaultdict(list)\n",
    "    vocab = set()\n",
    "\n",
    "    for doc, c in zip(D, C):\n",
    "        bigdoc[c].extend(doc)\n",
    "        vocab.update(doc)\n",
    "    \n",
    "    V = list(vocab)\n",
    "\n",
    "    for c in bigdoc:\n",
    "        Nc = C.count(c)\n",
    "        logprior[c] = math.log(Nc / N_doc)\n",
    "\n",
    "        word_counts = Counter(bigdoc[c])\n",
    "        denom = sum(word_counts[w] + 1 for w in V)\n",
    "\n",
    "        for w in V:\n",
    "            num = word_counts[w] + 1\n",
    "            loglikelihood[(w, c)] = math.log(num / denom)\n",
    "\n",
    "    return V, logprior, loglikelihood\n",
    "\n",
    "def test_naive_bayes(testdoc, logprior, loglikelihood, C, V, verbose=True):\n",
    "    \"\"\"\n",
    "    Clasifica un documento con el modelo entrenado.\n",
    "\n",
    "    Parámetros:\n",
    "    - testdoc: lista de palabras\n",
    "    - logprior, loglikelihood: parámetros entrenados\n",
    "    - C: lista de clases posibles\n",
    "    - V: vocabulario\n",
    "    - verbose: si True, imprime las probabilidades logarítmicas\n",
    "\n",
    "    Retorna:\n",
    "    - clase_predicha: clase con mayor score\n",
    "    \"\"\"\n",
    "    sum_scores = {}\n",
    "    V_set = set(V)\n",
    "\n",
    "    for c in C:\n",
    "        score = logprior[c]\n",
    "        for word in testdoc:\n",
    "            if word in V_set:\n",
    "                score += loglikelihood.get((word, c), 0.0)\n",
    "        sum_scores[c] = score\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Log-probabilidades por clase:\")\n",
    "        for c, score in sum_scores.items():\n",
    "            print(f\"  {c}: {score:.4f}\")\n",
    "\n",
    "    return max(sum_scores, key=sum_scores.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ec3d51",
   "metadata": {},
   "source": [
    "# Cross validation de naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0648898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_naive_bayes(docs, clases, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    total_aciertos = 0\n",
    "    total_instancias = 0\n",
    "    porcentajes = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(docs), 1):\n",
    "        D_train = [docs[i] for i in train_index]\n",
    "        C_train = [clases[i] for i in train_index]\n",
    "        D_test = [docs[i] for i in test_index]\n",
    "        C_test = [clases[i] for i in test_index]\n",
    "\n",
    "        V, logprior, loglikelihood = train_naive_bayes(D_train, C_train)\n",
    "\n",
    "        aciertos_fold = 0\n",
    "        for doc, true_class in zip(D_test, C_test):\n",
    "            pred = test_naive_bayes(doc, logprior, loglikelihood, list(set(C_train)), V, verbose=False)\n",
    "            if pred == true_class:\n",
    "                aciertos_fold += 1\n",
    "\n",
    "        porcentaje_fold = aciertos_fold / len(D_test)\n",
    "        porcentajes.append(porcentaje_fold)\n",
    "        total_aciertos += aciertos_fold\n",
    "        total_instancias += len(D_test)\n",
    "\n",
    "        print(f\"Fold {fold_idx}: {porcentaje_fold:.2%} de acierto ({aciertos_fold}/{len(D_test)})\")\n",
    "\n",
    "    exactitud_promedio = total_aciertos / total_instancias\n",
    "    print(f\"\\nExactitud promedio en {k}-fold cross-validation: {exactitud_promedio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a5a5639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 33.33% de acierto (1/3)\n",
      "Fold 2: 100.00% de acierto (2/2)\n",
      "Fold 3: 50.00% de acierto (1/2)\n",
      "Fold 4: 100.00% de acierto (2/2)\n",
      "Fold 5: 0.00% de acierto (0/2)\n",
      "\n",
      "Exactitud promedio en 5-fold cross-validation: 0.5455\n"
     ]
    }
   ],
   "source": [
    "docs = df['Documento'].apply(limpiar).tolist()\n",
    "clases = df['Clase'].tolist()\n",
    "\n",
    "cross_validate_naive_bayes(docs, clases, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a188fc1",
   "metadata": {},
   "source": [
    "# Binary naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f9cb7e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_binary_naive_bayes(D, C):\n",
    "    \"\"\"\n",
    "    Entrena un clasificador Binary Multinomial Naive Bayes con add-1 smoothing.\n",
    "    En este modelo solo se considera si una palabra aparece al menos una vez por documento.\n",
    "\n",
    "    Parámetros:\n",
    "    - D: lista de documentos (listas de palabras)\n",
    "    - C: lista de clases\n",
    "\n",
    "    Retorna:\n",
    "    - V: vocabulario (lista de palabras únicas)\n",
    "    - logprior: log P(c)\n",
    "    - loglikelihood: log P(w|c)\n",
    "    \"\"\"\n",
    "    N_doc = len(D)\n",
    "    logprior = {}\n",
    "    loglikelihood = {}\n",
    "    bigdoc = defaultdict(list)\n",
    "    vocab = set()\n",
    "    \n",
    "    bin_docs = [list(set(doc)) for doc in D]\n",
    "\n",
    "    for doc, c in zip(bin_docs, C):\n",
    "        bigdoc[c].extend(doc)\n",
    "        vocab.update(doc)\n",
    "    \n",
    "    V = list(vocab)\n",
    "    \n",
    "    for c in bigdoc:\n",
    "        Nc = C.count(c)\n",
    "        logprior[c] = math.log(Nc / N_doc)\n",
    "\n",
    "        word_counts = Counter(bigdoc[c])\n",
    "        denom = sum(word_counts[w] + 1 for w in V)  # add-1 smoothing\n",
    "\n",
    "        for w in V:\n",
    "            num = word_counts[w] + 1\n",
    "            loglikelihood[(w, c)] = math.log(num / denom)\n",
    "\n",
    "    return V, logprior, loglikelihood\n",
    "\n",
    "def test_naive_bayes(testdoc, logprior, loglikelihood, C, V, verbose=True):\n",
    "    \"\"\"\n",
    "    Clasifica un documento con el modelo entrenado.\n",
    "\n",
    "    Parámetros:\n",
    "    - testdoc: lista de palabras\n",
    "    - logprior, loglikelihood: parámetros entrenados\n",
    "    - C: lista de clases posibles\n",
    "    - V: vocabulario\n",
    "    - verbose: si True, imprime las probabilidades logarítmicas\n",
    "\n",
    "    Retorna:\n",
    "    - clase_predicha: clase con mayor score\n",
    "    \"\"\"\n",
    "    sum_scores = {}\n",
    "    V_set = set(V)\n",
    "\n",
    "    for c in C:\n",
    "        score = logprior[c]\n",
    "        for word in testdoc:\n",
    "            if word in V_set:\n",
    "                score += loglikelihood.get((word, c), 0.0)\n",
    "        sum_scores[c] = score\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Log-probabilidades por clase:\")\n",
    "        for c, score in sum_scores.items():\n",
    "            print(f\"  {c}: {score:.4f}\")\n",
    "\n",
    "    return max(sum_scores, key=sum_scores.get)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7becab",
   "metadata": {},
   "source": [
    "# Cross validation de binary naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e803ddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_binary_naive_bayes(docs, clases, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    total_aciertos = 0\n",
    "    total_instancias = 0\n",
    "    porcentajes = []\n",
    "\n",
    "    for fold_idx, (train_index, test_index) in enumerate(kf.split(docs), 1):\n",
    "        D_train = [docs[i] for i in train_index]\n",
    "        C_train = [clases[i] for i in train_index]\n",
    "        D_test = [docs[i] for i in test_index]\n",
    "        C_test = [clases[i] for i in test_index]\n",
    "\n",
    "        V, logprior, loglikelihood = train_binary_naive_bayes(D_train, C_train)\n",
    "\n",
    "        aciertos_fold = 0\n",
    "        for doc, true_class in zip(D_test, C_test):\n",
    "            doc_bin = list(set(doc)) \n",
    "            pred = test_naive_bayes(doc_bin, logprior, loglikelihood, list(set(C_train)), V, verbose=False)\n",
    "            if pred == true_class:\n",
    "                aciertos_fold += 1\n",
    "\n",
    "        porcentaje_fold = aciertos_fold / len(D_test)\n",
    "        porcentajes.append(porcentaje_fold)\n",
    "        total_aciertos += aciertos_fold\n",
    "        total_instancias += len(D_test)\n",
    "\n",
    "        print(f\"Fold {fold_idx}: {porcentaje_fold:.2%} de acierto ({aciertos_fold}/{len(D_test)})\")\n",
    "\n",
    "    exactitud_promedio = total_aciertos / total_instancias\n",
    "    print(f\"\\nExactitud promedio en {k}-fold cross-validation: {exactitud_promedio:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e096d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 33.33% de acierto (1/3)\n",
      "Fold 2: 100.00% de acierto (2/2)\n",
      "Fold 3: 50.00% de acierto (1/2)\n",
      "Fold 4: 100.00% de acierto (2/2)\n",
      "Fold 5: 0.00% de acierto (0/2)\n",
      "\n",
      "Exactitud promedio en 5-fold cross-validation: 0.5455\n"
     ]
    }
   ],
   "source": [
    "docs = df['Documento'].apply(limpiar).tolist()\n",
    "clases = df['Clase'].tolist()\n",
    "\n",
    "cross_validate_binary_naive_bayes(docs, clases, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
